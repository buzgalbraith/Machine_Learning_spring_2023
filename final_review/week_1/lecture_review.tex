\documentclass{article}
\usepackage[utf8]{inputenc}
\title{Lecture 1 intro to statistical learning theory}
\author{wbg231 }
\date{December 2022}
\newcommand{\R}{$\mathbb{R}$}
\newcommand{\B}{$\beta$}
\newcommand{\A}{$\alpha$}
\newcommand{\D}{\Delta}

\newcommand{\avector}[2]{(#1_2,\ldots,#1_{#2})}
\newcommand{\makedef}[2]{$\textbf{#1}$:#2 }

\usepackage{tikz,graphicx,hyperref,amsmath,amsfonts,amscd,amssymb,bm,cite,epsfig,epsf,url}

\begin{document}

\maketitle

\section{introduction}
\begin{itemize}
\item for stuff before the midterm i am going to review it pretty quickly unless it is really important 
\subsection*{decision theory definitions}
\item a prediction function gets input $x\in X$ as inputs and produces $a\in A$ $$f:X\rightarrow a$$
\item a loss function evaluates an action in the context of the outcome y that is $$\ell:A\times y\rightarrow \mathbb{R}$$
\item \textcolor{red}{risk} over a prediction function $f:X\rightarrow A$ is $$R(f)=E_{(x,y)\sim P_{x,y}}[\ell(f(x),y)]$$
\item we can not compute this in practice since we do not know the true data generating process
\item the bayes prediction function is the minimal risk prediction function that is $$f^{*}\in argmin_{i}R(f)$$
\item since we can not compute risk we can use the empirical risk of a function  $f:X\rightarrow A$ with respect to dataset D is $$\hat{R}_{n}(f)=\frac{1}{n}\Sigma_{i=1}^{n}\ell(f(x_i), y_i)$$
\item in other words it is the mean loss over our training data if we predict using that function 
\item the empirical risk minimizer is the the function $$\hat{f}\in argmin_{f}\hat{R}_{n}(f)$$
\item that is the function that could get the minimal risk on our training set 
\item in many cases unconstrained ERM will just memorize the training set, 
\item so to improve generalization we can use constrained ERM, that is instead of minimzed risk of all prediction functions we constrain our search space to a set of functions called the hypothesis space
\item so we can get constrained find our constrained empirical risk minizer as  $$\hat{f}_{n}\in argmin_{f\in \mathcal{F}}\hat{R}_{n}(f)$$ where $\mathcal{F}$ is our hypothesis space
\item a risk minimizer in $\mathcal{F}$ is $$f^{*}_{\mathcal{F}}\in argmin_{f\in \mathcal{F}}E[\ell(x),y]$$
\item \includegraphics*[width=10cm]{images/Screenshot 2023-05-10 at 8.02.37 PM.png}
\item as we can see our Approximation error is what we lose by specifying a hypothesis class 
\item our estimation error is the diference in how well our data could be fit by any function veruss the best in our hypothesis class
\item \textcolor{blue}{excess risk} is defined as $$R(f)-R(f*)$$ that is the diference in risk between our learned function and the bayes optimal one 
\item we can wrote excess risk as the sum of Approximation error and estimation error, so there is a trade off between the two 
\item a larger hypothesis space means smaller Approximation error (Approximation error is a non random variable it is a function of our hypothesis space)
\item estimation error goes up as our hypothesis space gets more complex. it is a random variable due as a function of our data
\item in practice we can not simply find and argmin in most cases so we call \textcolor{blue}{the optimization error} the difference  between the true empirical risk minimizer and what our optimization learned in practice
\item so overall we can think of excess risk = optimization error + estimation error + Approximation error 
\item we can not observe this in practice
\end{itemize}
\end{document}
